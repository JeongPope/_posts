---
layout: post
category: devlog
tags: devops kubernetes monitoring
title: "Deploying EFK(ElasticSearch + Fluentd + Kibana) Stack on EKS"
description: >
  EKS 탐방기 시리즈 - 2편
image:
  path: /assets/img/devlog/devops/kubernetes/2021-03-03/EFK stack/main.png
---

![Architecture](/assets/img/devlog/devops/kubernetes/2021-03-03/EFK stack/8.png){:.centered}
ElasticSearch + Fluentd + Kibana = EFK Stack 이라고 부른다.<br>
지속적으로 유입되는 로그 데이터를 수신하고 이 데이터를 차트와 그래프로 시각화하기 위해 사용한다.<br> 

Fluentd 는 `Logstash`로 대신해 사용할 수 있으며 `ELK Stack`이 된다.
{:.note}

데이터가 서버에 지속적으로 유입이 되어 데이터의 양이 늘어나면 서버는 데이터양을 감당하지 못할것이다.<br>
규모가 커질수록 분석속도가 느려지고 서버의 리소스가 감당하지 못할 것인데 이러한 데이터를 어떻게 감당할 수 있느냐? 이 문제에 대한 솔루션이 바로 EFK 스택이다.<br>

쿠버네티스는 Pod가 정상적인 상태가 아니면 힐링 작업을 하는데, 이때 Pod가 죽는 경우 컨테이너가 남긴 로그를 로그 저장소에 수집할 수 있다는 장점이 있다.

<!--more-->

***

### ElasticSearch : 로그를 저장하기 위한 대용량 저장소
![ElasticSearch](/assets/img/devlog/common/elasticsearch.png){:.centered}

#### 특징
1. 멀티테넌시
- 데이터를 여러개로 분리된 인덱스들의 그룹으로 저장
- 서로 다른 인덱스의 데이터를 하나의 쿼리로 검색하여 하나의 출력으로 도출가능하다.

2. 실시간 데이터 분석
- 저장된 데이터는 검색에 사용되기 위해 별도의 재시작 / 갱신이 불필요하다.
- 색인 작업이 완료됨과 동시에 바로 검색 가능하다.
- 실시간 분석 / 검색은 데이터 증가량에 구애받지 않는다.

3. 고가용성
- Elasticsearch는 하나 이상의 노드로 구성이 되고 각 노드는 1개 이상의 데이터 원본과 복사본을 서로 다른위치에 나누어 저장을하여 고가용성을 제공한다.
- 항상 일정한 데이터 복사본의 개수를 유지하여 높은 가용성과 안정성을 보장한다.
- 노드가 종료되거나 실행에 실패할 경우 다른 노드로 데이터를 이동한다.

4. 테이블이나 스키마 대신 JSON 형식으로 저장
- 기본적으로 모든 필드를 색인 후에 JSON 형식으로 저장한다. JSON 구조로 인해 모든 레벨의 필드에 접근이 쉽고, 빠른 속도로 검색이 가능해진다.
- JSON 문서를 URI로 명시, 이 문서를 처리하기 위해 HTTP 메소드를 이용한다.

#### YAML
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: elasticsearch
  labels:
    app: elasticsearch
spec:
  replicas: 1
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: elastic/elasticsearch:6.4.0
        env:
        - name: discovery.type
          value: "single-node"
        ports:
        - containerPort: 9200
        - containerPort: 9300
        
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: elasticsearch
  name: elasticsearch-svc
  namespace: default
spec:
  ports:
  - name: elasticsearch-rest
    nodePort: 30920         # Node Port
    port: 9200              # Service Port
    protocol: TCP
    targetPort: 9200        # Pod Port
  - name: elasticsearch-nodecom
    nodePort: 30930
    port: 9300
    protocol: TCP
    targetPort: 9300
  selector:
    app: elasticsearch
  type: NodePort
```
LB에 리스너를 추가해준다. 정의된 규칙에 따라 로드밸런서가 등록 대상으로 들어오는 요청을 라우팅해준다.
{:.note}

* Network
1. Load Balancer (Port : 9200) > NodePort (Port : 30920)
2. NodePort (Port : 30920) > Service (Port : 9200)
3. Service (Port : 9200) > ElasticSearch Pod (Port : 9200)

```shell
[admin@ip-10-0-0-51 ~]$ kubectl apply -f elasticSearch.yaml
deployment.apps/elasticsearch created
service/elasticsearch-svc created
[admin@ip-10-0-0-51 ~]$ kubectl get pod
NAME                             READY   STATUS    RESTARTS   AGE
elasticsearch-7fb97d9555-78gl5   1/1     Running   0          59s
my-nginx-75897978cd-6qps2        1/1     Running   0          10m
my-nginx-75897978cd-9g9st        1/1     Running   0          10m
[admin@ip-10-0-0-51 ~]$ kubectl get service
NAME                TYPE           CLUSTER-IP      EXTERNAL-IP                                                                   PORT(S)                         AGE
elasticsearch-svc   NodePort       10.100.80.173   <none>                                                                        9200:30920/TCP,9300:30930/TCP   64s
kubernetes          ClusterIP      10.100.0.1      <none>                                                                        443/TCP                         22m
my-nginx            LoadBalancer   10.100.138.30   ab.......................................80.ap-northeast-2.elb.amazonaws.com   80:32404/TCP                    8m52s
```

External IP:9200 접근 시 아래와 같은 JSON을 볼 수 있다.
```json
{
  "name" : "uXltMgW",
  "cluster_name" : "docker-cluster",
  "cluster_uuid" : "NupHNbOCTkuX3KnXajPxgw",
  "version" : {
    "number" : "6.4.0",
    "build_flavor" : "default",
    "build_type" : "tar",
    "build_hash" : "595516e",
    "build_date" : "2018-08-17T23:18:47.308994Z",
    "build_snapshot" : false,
    "lucene_version" : "7.4.0",
    "minimum_wire_compatibility_version" : "5.6.0",
    "minimum_index_compatibility_version" : "5.0.0"
  },
  "tagline" : "You Know, for Search"
}
```

### Kibana
![Kibana](/assets/img/devlog/common/kibana.png){:.centered}
Kibana는 그래프, 차트를 제공해주는 Elasicsearch용 데이터 시각화 관리도구입니다.<br>
Kibana를 사용하여 Elasticsearch 색인에 저장된 데이터를 검색할 수 있고, 웹 사이트 방문자를 표시할 수도 있고 트래픽을 실시간으로 볼 수도 있습니다.

#### YAML
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  labels:
    app: kibana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      containers:
      - name: kibana
        image: elastic/kibana:6.4.0
        env:
        - name: SERVER_NAME
          value: "kibana.kubenetes.example.com"
        - name: ELASTICSEARCH_URL
          value: "http://elasticsearch-svc.default.svc.cluster.local:9200"
        ports:
        - containerPort: 5601

---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: kibana
  name: kibana-svc
  namespace: default
spec:
  ports:
  - nodePort: 30561
    port: 5601
    protocol: TCP
    targetPort: 5601
  selector:
    app: kibana
  type: NodePort
```

* Network
1. Load Balancer (Port : 5601) > NodePort (Port : 30561)
2. NodePort (Port : 30561) > Service (Port : 5601)
3. Service (Port : 5601) > ElasticSearch Pod (Port : 5601)

```shell
[admin@ip-10-0-0-51 ~]$ kubectl apply -f kibana.yaml
deployment.apps/kibana created
service/kibana-svc created
[admin@ip-10-0-0-51 ~]$ kubectl get pod
NAME                             READY   STATUS    RESTARTS   AGE
elasticsearch-7fb97d9555-xvnfh   1/1     Running   0          3m29s
kibana-74fc787497-wfrcg          1/1     Running   0          5s
my-nginx-75897978cd-6qps2        1/1     Running   0          29m
my-nginx-75897978cd-9g9st        1/1     Running   0          29m
[admin@ip-10-0-0-51 ~]$ kubectl get service
NAME                TYPE           CLUSTER-IP      EXTERNAL-IP                                                                   PORT(S)                         AGE
elasticsearch-svc   NodePort       10.100.14.128   <none>                                                                        9200:30920/TCP,9300:30930/TCP   2m59s
kibana-svc          NodePort       10.100.42.223   <none>                                                                        5601:30561/TCP                  17s
kubernetes          ClusterIP      10.100.0.1      <none>                                                                        443/TCP                         41m
my-nginx            LoadBalancer   10.100.138.30   ab.......................................80.ap-northeast-2.elb.amazonaws.com   80:32404/TCP                    27m
```



### fluentd
![Fluentd](/assets/img/devlog/common/fluentd.png){:.centered}

Fluentd는 로그 데이터를 수집, 변환(HTTP, TCP 등 원하는 형태로 가공) 후 Elasticsearch의 백엔드로 전송해주는 역할을 하는 오픈소스 데이터 수집기이다.<br>
데이터 유실을 막기위해 메모리와 파일기반의 Buffer 시스템을 갖고있으며, Failover를 위한 HA구성도 가능합니다.<br>

`Fluentd`는 모든 노드마다 동일하게 배포되어야 하므로 `Daemonset`으로 배포합니다.<br>

* Daemonset
1. 쿠버네티스 컨트롤러(Deployment, ReplicaSet 등) 중 하나로 컨트롤러란 쿠버네티스 기본 object를 생성하고 관리하는 역할을 수행합니다.
2. Daemonset은 Pod가 각각의 노드에 하나씩만 배포되게 하는 Pod 관리 컨트롤러

#### YAML
```yaml
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd
  namespace: kube-system

---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: fluentd
  namespace: kube-system
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - namespaces
  verbs:
  - get
  - list
  - watch

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: fluentd
roleRef:
  kind: ClusterRole
  name: fluentd
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: fluentd
  namespace: kube-system

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
  labels:
    k8s-app: fluentd-logging
    version: v1
    kubernetes.io/cluster-service: "true"
spec:
  selector:
    matchLabels:
      k8s-app: fluentd-logging
      version: v1
  template:
    metadata:
      labels:
        k8s-app: fluentd-logging
        version: v1
        kubernetes.io/cluster-service: "true"
    spec:
      serviceAccount: fluentd
      serviceAccountName: fluentd
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1.4.2-debian-elasticsearch-1.1
        env:
          - name:  FLUENT_ELASTICSEARCH_HOST
            value: "elasticsearch-svc.default.svc.cluster.local"
          - name:  FLUENT_ELASTICSEARCH_PORT
            value: "9200"
          - name: FLUENT_ELASTICSEARCH_SCHEME
            value: "http"
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      terminationGracePeriodSeconds: 30
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
```

```shell
[admin@ip-10-0-0-51 ~]$ kubectl apply -f fluentd.yaml
serviceaccount/fluentd created
clusterrole.rbac.authorization.k8s.io/fluentd created
clusterrolebinding.rbac.authorization.k8s.io/fluentd created
daemonset.apps/fluentd created
[admin@ip-10-0-0-51 ~]$ kubectl get pod -n kube-system
NAME                      READY   STATUS    RESTARTS   AGE
aws-node-m4pnk            1/1     Running   0          39m
coredns-7dd7f84d9-6r5nr   1/1     Running   0          46m
coredns-7dd7f84d9-p2vr7   1/1     Running   0          46m
fluentd-49f5r             1/1     Running   0          14s
kube-proxy-lpfws          1/1     Running   0          39m
[admin@ip-10-0-0-51 ~]$ 
```

### TOOD
1. `Kibana` Index pattern 설정
2. 로그 시각화 확인

### Reference
- [velog](https://velog.io/@seunghyeon/0.-EFK-스택구축-EFK스택)